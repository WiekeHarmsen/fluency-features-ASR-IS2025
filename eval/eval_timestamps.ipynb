{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This scripts gets as input two csv files (ref and hyp) with the following structure:\n",
    "\n",
    "    word    begin   end\n",
    "    ik      0.2     0.3\n",
    "    begin   0.3     0.35\n",
    "    etc.\n",
    "\n",
    "JASMIN reference files are created here: fluency-features-using-ASR/ref_fluency_scripts/01-pace-phrasing-from-tg.ipynb\n",
    "JASMIN ASR files are created here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNrTPs(asrDF, otDF, collar):\n",
    "\n",
    "    TP_counter = 0\n",
    "\n",
    "    for idx, row in asrDF.iterrows():\n",
    "\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        textNorm = row['text_norm']\n",
    "\n",
    "        acceptable_start_begintime = start - collar\n",
    "        acceptable_end_begintime = start + collar\n",
    "        acceptable_start_endtime = end - collar\n",
    "        acceptable_end_endtime = end + collar\n",
    "\n",
    "        # Select all rows in otDF that fall within the acceptable_start collar and acceptable_end collar\n",
    "        otDF_sel = otDF[(otDF['start'] >= acceptable_start_begintime) & (otDF['start'] <= acceptable_end_begintime) & (otDF['end'] >= acceptable_start_endtime) & (otDF['end'] <= acceptable_end_endtime) & (otDF['text_norm'] == textNorm)]\n",
    "\n",
    "        if len(otDF_sel) > 0:\n",
    "            TP_counter += 1\n",
    "\n",
    "    return TP_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(asrDfFiles, collar, outputDirMetrics, otDfDir):\n",
    "\n",
    "    outputList = []\n",
    "\n",
    "    for asrDfFile in asrDfFiles:\n",
    "        # Get basename\n",
    "        basename = os.path.basename(asrDfFile).replace('.tsv', '')\n",
    "\n",
    "        # Get corresponding orth. trans. file\n",
    "        otDfFile = os.path.join(otDfDir, basename + '.tsv')\n",
    "        assert os.path.exists(otDfFile), 'OT file ' + basename + ' does not exist.'\n",
    "\n",
    "        # Read both files\n",
    "        asrDF = pd.read_csv(asrDfFile, index_col = 0, sep='\\t')\n",
    "        otDF = pd.read_csv(otDfFile, index_col = 0, sep='\\t')\n",
    "\n",
    "        # PREPROCESS FOR COMPARISON\n",
    "        otDF = otDF.rename(columns = {'start_time': 'start', 'end_time': 'end'})\n",
    "\n",
    "        # Compute Precision (DF1 = asrDF)\n",
    "        TP_counter = computeNrTPs(asrDF, otDF, collar)\n",
    "\n",
    "        precision = round(TP_counter / len(asrDF), 4)\n",
    "\n",
    "        recall = round(TP_counter /len (otDF), 4)\n",
    "\n",
    "        try:\n",
    "\n",
    "            F1 = round((2*precision*recall)/(precision+recall), 4)\n",
    "\n",
    "        except:\n",
    "            F1 = np.nan\n",
    "\n",
    "        outputList.append([basename, collar, precision, recall, F1, TP_counter, len(asrDF), len(otDF)])\n",
    "\n",
    "    outputDF = pd.DataFrame(outputList, columns= ['audioID', 'collar', 'precision', 'recall', 'F1', 'TP_counter', 'lenAsrDF', 'lenOtDF'])\n",
    "    outputDF.to_csv(os.path.join(outputDirMetrics, 'test_metrics_'+str(collar)+'.tsv'), sep='\\t')\n",
    "\n",
    "    return outputDF['F1'].mean(), outputDF['F1'].std(), outputDF['precision'].mean(), outputDF['precision'].std(), outputDF['recall'].mean(), outputDF['recall'].std(), outputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = '/vol/tensusers2/wharmsen/JASMIN-fluency-features/comp-q-read_nl_age7-11_nat-new'\n",
    "# basePath = '/vol/tensusers2/wharmsen/JASMIN-fluency-features/comp-q-read_vl_age7-11_nat-new'\n",
    "corpus = 'jasmin'\n",
    "\n",
    "# basePath = '/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-new'\n",
    "# corpus = 'serda'\n",
    "\n",
    "recordingsPath = os.path.join(basePath, '03_metadata/recordingsDF.tsv')\n",
    "recordingsDF = pd.read_csv(recordingsPath, index_col=0, sep='\\t')\n",
    "\n",
    "asrSystems = ['whispert', 'whispert_dis', 'whispert_vad_dis', 'whispert_prompts']\n",
    "\n",
    "metricsOverviewList = []\n",
    "metricsFileDFList = []\n",
    "for asrSystem in asrSystems:\n",
    "\n",
    "    \"\"\"\n",
    "    Define input paths\n",
    "    \"\"\"\n",
    "    asrDfDir = os.path.join(basePath, '04_asr/' + asrSystem + '/timestamps-words')\n",
    "    otDfDir = os.path.join(basePath, '06_manual_fluency_features/json-orth-trans')\n",
    "    \n",
    "    \"\"\"\n",
    "    Define output paths\n",
    "    \"\"\"\n",
    "    outputDirMetrics = os.path.join(basePath, '04_asr/' + asrSystem + '/report_time_eval')\n",
    "    if not os.path.exists(outputDirMetrics):\n",
    "        os.makedirs(outputDirMetrics)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Perform the analysis\n",
    "    \"\"\"\n",
    "\n",
    "    if corpus == 'jasmin':\n",
    "        asrDfFiles = glob.glob(os.path.join(asrDfDir, '*story[1-2].tsv'))\n",
    "    elif corpus == 'serda':\n",
    "        asrDfFiles = glob.glob(os.path.join(asrDfDir, '*.tsv'))\n",
    "    print(len(asrDfFiles), 'asrDF files', os.path.join(asrDfDir, '*.tsv'))\n",
    "\n",
    "    for collar in np.arange(0.2, 0.4, 0.1):\n",
    "        F1_mean, F1_std, Prec_mean, Prec_std, Recall_mean, Recall_std, metricsFileDF = computeMetrics(asrDfFiles, collar, outputDirMetrics, otDfDir)\n",
    "        metricsOverviewList.append([asrSystem, collar, F1_mean, F1_std, Prec_mean, Prec_std, Recall_mean, Recall_std])\n",
    "        metricsFileDF['asrSystem'] = [asrSystem] * len(metricsFileDF)\n",
    "        metricsFileDFList.append(metricsFileDF)\n",
    "\n",
    "metricsOverviewDF = pd.DataFrame(metricsOverviewList, columns=['asrSystem', 'collar','F1_mean', 'F1_std', 'Prec_mean', 'Prec_std', 'Recall_mean', 'Recall_std'])\n",
    "metricsOverviewDF.to_csv(os.path.join(basePath, '04_asr/timingAccMetricsOverviewDF.tsv'), sep='\\t')\n",
    "\n",
    "metricsDF = pd.concat(metricsFileDFList)\n",
    "metricsDF.to_csv(os.path.join(basePath, '04_asr/timingAccMetricsDF.tsv'), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
