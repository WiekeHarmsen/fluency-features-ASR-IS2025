{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import tgt\n",
    "\n",
    "# from utils import read_textgrids as rf\n",
    "import utils.sclite_string_normalizer as sclite_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read textgrid and extract begin/end time of first three sentences\n",
    "def read_tg_file_to_df_jasmin(tg_file):\n",
    "\n",
    "    # Read TextGrid file\n",
    "    try:\n",
    "        tg = tgt.io.read_textgrid(tg_file, encoding='utf-8', include_empty_intervals=False)\n",
    "    except:\n",
    "        tg = tgt.io.read_textgrid(tg_file, encoding='utf-16', include_empty_intervals=False)\n",
    "\n",
    "    # Convert TextGrid file to Formatted Table (= df with on each row one interval)\n",
    "    table = tgt.io.export_to_table(tg, separator='\\t')\n",
    "    formatted_table = [x.split('\\t') for x in table.split('\\n')]\n",
    "\n",
    "    return pd.DataFrame(formatted_table[1:], columns = formatted_table[0])\n",
    "\n",
    "# Read textgrid and extract begin/end time of first three sentences\n",
    "def read_tg_file_to_df(tg_file, file_encoding):\n",
    "\n",
    "    # Read TextGrid file\n",
    "    tg = tgt.io.read_textgrid(tg_file, encoding = file_encoding, include_empty_intervals=False)\n",
    "\n",
    "    # Convert TextGrid file to Formatted Table (= df with on each row one interval)\n",
    "    table = tgt.io.export_to_table(tg, separator='; ')\n",
    "    formatted_table = [x.split('; ') for x in table.split('\\n')]\n",
    "    df = pd.DataFrame(formatted_table[1:], columns = formatted_table[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextGridFile(tgFile, corpus):\n",
    "    # Read TextGrid file\n",
    "    if corpus == 'serda' or corpus == 'dart':\n",
    "        tg_df = read_tg_file_to_df(tgFile, 'latin-1')\n",
    "    elif corpus == 'jasmin':\n",
    "        tg_df = read_tg_file_to_df_jasmin(tgFile)\n",
    "    return tg_df.astype({'start_time':float, 'end_time':float} )\n",
    "\n",
    "def selectWordTierTextGrid(tg_df, word_tier_name):\n",
    "    return tg_df[tg_df['tier_name'] == word_tier_name]\n",
    "\n",
    "def splitTextDFIntoSentences(tg_df_orth_trans):\n",
    "    sentenceDFList = []\n",
    "    tg_df_orth_trans = tg_df_orth_trans.reset_index()\n",
    "    startIDX = tg_df_orth_trans.index[0]\n",
    "    for idx, row in tg_df_orth_trans.iterrows():\n",
    "        if row['text'][-1] in ['.', '!', '?']:\n",
    "            sentenceDFList.append(tg_df_orth_trans.loc[startIDX:idx, :])\n",
    "            startIDX = idx+1\n",
    "        # If last sentence does not end with . ? or !\n",
    "        elif len(tg_df_orth_trans)-1 == idx:\n",
    "            sentenceDFList.append(tg_df_orth_trans.loc[startIDX:idx, :])\n",
    "            startIDX = idx+1\n",
    "    return sentenceDFList\n",
    "\n",
    "def wordRowToWordSegment(row):\n",
    "    # Remove annotation tags (*u, *a, etc.), remove all punctuation except the basic punctuation (!-'.?) and all default normalization steps (poss. pronouns, names, spelling errors, write numbers as words)\n",
    "    # w = sclite_norm.normalize_string(row['text'], annTags=True, all_punct=False, basic_punct=True)\n",
    "    w = sclite_norm.normalize_string(row['text'], annTags=True, all_punct=False, basic_punct=True, names_as_prompt = False)\n",
    "\n",
    "    if ' ' in w:\n",
    "        print(w)\n",
    "\n",
    "    return {\n",
    "                \"text\": w.replace(' ', ''),\n",
    "                \"start\": row['start_time'],\n",
    "                \"end\": row['end_time'],\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "\n",
    "\n",
    "def turnSentenceDFIntoSegment(sentenceDF, sentenceNr):\n",
    "\n",
    "    # Remove _ words, these are noisy areas before/after words\n",
    "    sentenceDF = sentenceDF[sentenceDF['text'] != '_']\n",
    "\n",
    "    wordsList = list(sentenceDF.apply(wordRowToWordSegment, axis=1))\n",
    "\n",
    "    return {\n",
    "            \"id\": sentenceNr,\n",
    "            \"seek\": 0,\n",
    "            \"start\": sentenceDF.loc[sentenceDF.index[0], 'start_time'],\n",
    "            \"end\": sentenceDF.loc[sentenceDF.index[-1], 'end_time'],\n",
    "            \"text\": \" \".join([x['text'] for x in wordsList]),\n",
    "            \"words\": wordsList\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare JASMIN-NL and JASMIN-VL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z egt\n",
      "b il\n",
      "l et\n",
      "j jan\n",
      "laa t\n",
      "klim op school\n",
      "z oek t\n",
      "klim scho\n",
      "bus hak\n",
      "klim op\n",
      "kind je\n",
      "mama s\n",
      "nee ee\n",
      "s sjort\n",
      "nee ee\n",
      "schoola arts\n",
      "b bril\n",
      "re reporter\n",
      "gei nig\n",
      "uit kiezen\n",
      "kamer ploeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidOperation\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/fluency-features-ASR-IS2025/utils/sclite_string_normalizer.py:135\u001b[0m, in \u001b[0;36mnormalize_string\u001b[0;34m(sentence, all_punct, basic_punct, lower, accents, number_to_letter, names_as_prompt, poss_pro, annTags, apostrophe_spelling_error)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[43mnum2words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/num2words/__init__.py:102\u001b[0m, in \u001b[0;36mnum2words\u001b[0;34m(number, ordinal, lang, to, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(number, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_to_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# backwards compatible\u001b[39;00m\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/num2words/base.py:101\u001b[0m, in \u001b[0;36mNum2Word_Base.str_to_number\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstr_to_number\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDecimal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInvalidOperation\u001b[0m: [<class 'decimal.ConversionSyntax'>]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m sentenceDFList \u001b[38;5;241m=\u001b[39m splitTextDFIntoSentences(tg_df_orth_trans)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Change each sentenceDF to a segment\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m segmentList \u001b[38;5;241m=\u001b[39m [turnSentenceDFIntoSegment(sentenceDF, sentenceNr) \u001b[38;5;28;01mfor\u001b[39;00m sentenceNr, sentenceDF \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentenceDFList)]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Save output as Dict\u001b[39;00m\n\u001b[1;32m     65\u001b[0m tgDict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([segment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segmentList]),\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m : segmentList,\n\u001b[1;32m     68\u001b[0m }\n",
      "Cell \u001b[0;32mIn[50], line 62\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m sentenceDFList \u001b[38;5;241m=\u001b[39m splitTextDFIntoSentences(tg_df_orth_trans)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Change each sentenceDF to a segment\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m segmentList \u001b[38;5;241m=\u001b[39m [\u001b[43mturnSentenceDFIntoSegment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentenceDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentenceNr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentenceNr, sentenceDF \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentenceDFList)]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Save output as Dict\u001b[39;00m\n\u001b[1;32m     65\u001b[0m tgDict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([segment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segmentList]),\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m : segmentList,\n\u001b[1;32m     68\u001b[0m }\n",
      "Cell \u001b[0;32mIn[45], line 47\u001b[0m, in \u001b[0;36mturnSentenceDFIntoSegment\u001b[0;34m(sentenceDF, sentenceNr)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mturnSentenceDFIntoSegment\u001b[39m(sentenceDF, sentenceNr):\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Remove _ words, these are noisy areas before/after words\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     sentenceDF \u001b[38;5;241m=\u001b[39m sentenceDF[sentenceDF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m     wordsList \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43msentenceDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwordRowToWordSegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: sentenceNr,\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m: wordsList\n\u001b[1;32m     56\u001b[0m     }\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/virenv-fluency/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[45], line 29\u001b[0m, in \u001b[0;36mwordRowToWordSegment\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwordRowToWordSegment\u001b[39m(row):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Remove annotation tags (*u, *a, etc.), remove all punctuation except the basic punctuation (!-'.?) and all default normalization steps (poss. pronouns, names, spelling errors, write numbers as words)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# w = sclite_norm.normalize_string(row['text'], annTags=True, all_punct=False, basic_punct=True)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43msclite_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannTags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_punct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasic_punct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_as_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m w:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(w)\n",
      "File \u001b[0;32m/vol/tensusers5/wharmsen/fluency-features-ASR-IS2025/utils/sclite_string_normalizer.py:135\u001b[0m, in \u001b[0;36mnormalize_string\u001b[0;34m(sentence, all_punct, basic_punct, lower, accents, number_to_letter, names_as_prompt, poss_pro, annTags, apostrophe_spelling_error)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m number_to_letter:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m         word \u001b[38;5;241m=\u001b[39m \u001b[43mnum2words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         word \u001b[38;5;241m=\u001b[39m word\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### Define inputs ###\n",
    "#####################\n",
    "\n",
    "# Read recordingsDF\n",
    "# basePath = '/vol/tensusers2/wharmsen/JASMIN-fluency-features/comp-q-read_nl_age7-11_nat-nonorm'\n",
    "basePath = '/vol/tensusers2/wharmsen/JASMIN-fluency-features/comp-q-read_vl_age7-11_nat-nonorm'\n",
    "recDF_path = os.path.join(basePath, '03_metadata/recordingsDF.tsv')\n",
    "\n",
    "# Set corresponding TextGrid dir with orthographic transcriptions\n",
    "tgDir = os.path.join(basePath, '00_orig_data/textgrids')\n",
    "tgExtension = '_updated.TextGrid'\n",
    "\n",
    "# Set corpus\n",
    "corpus = 'jasmin'\n",
    "\n",
    "# Create output dir\n",
    "outputDir = os.path.join(basePath, '06_manual_fluency_features/json-orth-trans')\n",
    "\n",
    "# Define output transcription files\n",
    "otTrans_norm = []\n",
    "outputTranscriptsNormFile = os.path.join(basePath, '06_manual_fluency_features/ot-norm.csv')\n",
    "\n",
    "\n",
    "#########################\n",
    "### Create JSON files ###\n",
    "#########################\n",
    "\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "# Read recordingsDF\n",
    "recDF = pd.read_csv(recDF_path, sep= '\\t', index_col=0)\n",
    "\n",
    "for audioID, row in recDF.iterrows():\n",
    "\n",
    "    # Extract appropriate metadata of each recording\n",
    "    startTimeRec = row['startTimeFirstSent']\n",
    "    endTimeRec = row['endTimeLastSent']\n",
    "    cutStart = row['cutStart']\n",
    "    cutEnd = row['cutEnd']\n",
    "    totalDuration = row['duration']\n",
    "\n",
    "    # Read TextGrid File\n",
    "    aviLevel = audioID.split('-')[1].split('_')[0].replace('AVI', 'AVI ')\n",
    "    recordingID = row['recordingID']\n",
    "    tgFile = os.path.join(tgDir, aviLevel + '/' + recordingID + tgExtension)\n",
    "    tg_df = readTextGridFile(tgFile, corpus)\n",
    "    word_tier_name = tg_df.loc[0,'tier_name']\n",
    "    tg_df_orth_trans = selectWordTierTextGrid(tg_df, word_tier_name)\n",
    "\n",
    "    # Only JASMIN: select part of TextGrid that belongs to the specific story and correct the time stamps\n",
    "    tg_df_orth_trans = tg_df_orth_trans[tg_df_orth_trans['start_time']>=cutStart]\n",
    "    tg_df_orth_trans = tg_df_orth_trans[tg_df_orth_trans['end_time']<=cutEnd]\n",
    "    tg_df_orth_trans['start_time'] = tg_df_orth_trans['start_time'] - cutStart\n",
    "    tg_df_orth_trans['end_time'] = tg_df_orth_trans['end_time'] - cutStart\n",
    "\n",
    "    # Split textDF into sentences\n",
    "    sentenceDFList = splitTextDFIntoSentences(tg_df_orth_trans)\n",
    "\n",
    "    # Change each sentenceDF to a segment\n",
    "    segmentList = [turnSentenceDFIntoSegment(sentenceDF, sentenceNr) for sentenceNr, sentenceDF in enumerate(sentenceDFList)]\n",
    "\n",
    "    # Save output as Dict\n",
    "    tgDict = {\n",
    "        \"text\" : \" \".join([segment['text'] for segment in segmentList]),\n",
    "        \"segments\" : segmentList,\n",
    "    }\n",
    "\n",
    "    # OUTPUT 1: original transcriptions\n",
    "    # otTrans_norm.append([audioID, sclite_norm.normalize_string(tgDict['text'])])\n",
    "    otTrans_norm.append([audioID, sclite_norm.normalize_string(tgDict['text'], names_as_prompt = False)])\n",
    "\n",
    "\n",
    "    # OUTPUT 2: Write tgDict as json file\n",
    "    outputFile = os.path.join(outputDir, audioID + '.json')\n",
    "    # Check if file already exists, if it does, only dump file if current raterNr == 1 (Some files are rated by two raters, we only use the ratings by rater A01 (raterNr = 1))\n",
    "    with open(outputFile, \"w\") as outfile:\n",
    "        json.dump(tgDict, outfile, indent=4)\n",
    "\n",
    "print(str(len(glob.glob(os.path.join(outputDir, '*.json')))) + ' .json files created in '+ outputDir)\n",
    "\n",
    "# Write ot-norm file\n",
    "otTrans_norm_DF = pd.DataFrame(otTrans_norm, columns=['audioID', 'orthographic_transcription'])\n",
    "otTrans_norm_DF.to_csv(outputTranscriptsNormFile, index=False)\n",
    "print(outputTranscriptsNormFile, 'file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-\\'.?)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare SERDA-comp1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 TextGrid files found\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/QPPY5-story_2-20230120114816570_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/QTB2S-story_3-20221216105258185_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/SMVCS-story_1-20221103091343185_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/VJCMQ-story_2-20221123111647247_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/WHHXX-story_3-20221107134241743_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/XSWMB-story_1-20221216115257809_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YHTKC-story_1-20221117135859005_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YJ3PN-story_2-20230109112554434_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YKGD3-story_3-20221213115329236_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YKKTR-story_1-20221128103838446_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YMRDV-story_2-20221107093630712_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YQFGF-story_3-20230116132345386_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YVBRP-story_3-20230117092704671_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YVBRP-story_3-20230117092704671_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YWPWY-story_2-20230120093546063_A01_full_punct.TextGrid\n",
      "an der wets\n",
      "h hoor\n",
      "be kijkt\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/YWPWY-story_2-20230120093546063_A03_orth.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/Z2BYD-story_1-20221212135752996_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/Z2BYD-story_1-20221212135752996_A03_orth_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/ZDPNZ-story_1-20221107124621000_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/ZMQG2-story_2-20221128114456538_A01_full_punct.TextGrid\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/00_orig_data/textgrids/ZNNGY-story_3-20230110103621268_A01_full_punct.TextGrid\n",
      "18 .json files created in /vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/06_manual_fluency_features/json-orth-trans\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/06_manual_fluency_features/ot-norm.csv file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-'.?)\n",
      "/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm/06_manual_fluency_features/ot-all.csv file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-'.?)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### Define inputs ###\n",
    "#####################\n",
    "\n",
    "corpus = 'serda'\n",
    "basePath = '/vol/tensusers2/wharmsen/SERDA-fluency-features/comp1-nonorm'\n",
    "tgFileDir = os.path.join(basePath, '00_orig_data/textgrids')\n",
    "tgFileExtension = '.TextGrid'\n",
    "outputDir = os.path.join(basePath, '06_manual_fluency_features/json-orth-trans')\n",
    "word_tier_name = 'attempts'\n",
    "\n",
    "#########################\n",
    "### Create JSON files ###\n",
    "#########################\n",
    "\n",
    "# Create output dir\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "# Define output transcription files\n",
    "otTrans_norm = []\n",
    "otTrans_allFiles = []\n",
    "outputTranscriptsNormFile = os.path.join(basePath, '06_manual_fluency_features/ot-norm.csv')\n",
    "outputTranscriptsAllFile = os.path.join(basePath, '06_manual_fluency_features/ot-all.csv')\n",
    "\n",
    "# List all .TextGrid files\n",
    "# textgridFiles = glob.glob(os.path.join(tgFileDir, 'ZNNGY-story_3-20230110103621268_A01_full_punct*' + tgFileExtension))\n",
    "textgridFiles = glob.glob(os.path.join(tgFileDir, '*' + tgFileExtension))\n",
    "print(len(textgridFiles), 'TextGrid files found')\n",
    "\n",
    "for tgFile in textgridFiles:\n",
    "    print(tgFile)\n",
    "\n",
    "    # Read TextGrid file\n",
    "    tg_df = readTextGridFile(tgFile, corpus)\n",
    "    tg_df_orth_trans = selectWordTierTextGrid(tg_df, word_tier_name)\n",
    "\n",
    "    # Split textDF into sentences\n",
    "    sentenceDFList = splitTextDFIntoSentences(tg_df_orth_trans)\n",
    "\n",
    "    # Change each sentenceDF to a segment\n",
    "    segmentList = [turnSentenceDFIntoSegment(sentenceDF, sentenceNr) for sentenceNr, sentenceDF in enumerate(sentenceDFList)]\n",
    "\n",
    "    # Save output as Dict\n",
    "    tgDict = {\n",
    "        \"text\" : \" \".join([segment['text'] for segment in segmentList]),\n",
    "        \"segments\" : segmentList,\n",
    "    }   \n",
    "\n",
    "    # OUTPUTS\n",
    "    basename = os.path.basename(tgFile).split('_A0')[0]\n",
    "    raterNr = os.path.basename(tgFile).split('_A0')[1][0]\n",
    "\n",
    "    # OUTPUT 1: Original transcriptions\n",
    "    # otTrans_allFiles.append([os.path.basename(tgFile).replace('.TextGrid', ''), sclite_norm.normalize_string(tgDict['text'])])\n",
    "    otTrans_allFiles.append([os.path.basename(tgFile).replace('.TextGrid', ''), sclite_norm.normalize_string(tgDict['text'], names_as_prompt=False)])\n",
    "\n",
    "    recID = basename.split('-2')[0]\n",
    "    if recID not in ['Z2BYD-story_1', 'YWPWY-story_2', 'YVBRP-story_3'] or raterNr == '1':\n",
    "        # otTrans_norm.append([basename, sclite_norm.normalize_string(tgDict['text'])])\n",
    "        otTrans_norm.append([basename, sclite_norm.normalize_string(tgDict['text'], names_as_prompt=False)])\n",
    "\n",
    "\n",
    "    # OUTPUT 2: Write tgDict as json file\n",
    "    outputFile = os.path.join(outputDir, basename + '.json')\n",
    "\n",
    "    # Check if file already exists, if it does, only dump file if current raterNr == 1 (Some files are rated by two raters, we only use the ratings by rater A01 (raterNr = 1))\n",
    "    if (not os.path.exists(outputFile)) or (os.path.exists(outputFile) and raterNr == '1'):\n",
    "        with open(outputFile, \"w\") as outfile:\n",
    "            json.dump(tgDict, outfile, indent=4)\n",
    "\n",
    "print(str(len(glob.glob(os.path.join(outputDir, '*.json')))) + ' .json files created in '+ outputDir)\n",
    "\n",
    "# Write ot-norm file\n",
    "otTrans_norm_DF = pd.DataFrame(otTrans_norm, columns=['audioID', 'orthographic_transcription']).set_index('audioID').sort_index()\n",
    "otTrans_norm_DF.to_csv(outputTranscriptsNormFile)\n",
    "print(outputTranscriptsNormFile, 'file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-\\'.?)')\n",
    "\n",
    "# Write ot-all file\n",
    "otTrans_all_DF = pd.DataFrame(otTrans_allFiles, columns=['audioID', 'orthographic_transcription']).set_index('audioID').sort_index()\n",
    "otTrans_all_DF.to_csv(outputTranscriptsAllFile)\n",
    "print(outputTranscriptsAllFile, 'file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-\\'.?)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DART test data (annotations of 62 annotations of 60 audio files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 TextGrid files found\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/18103-posttest1-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "lesje kijken la hagel jaap sterk bestaat buren duik stoei ka krachken swink boomstam warmst jonge web zieke rechtsaf sap sterhun nieuw juicht vorst stuurdam blij\n",
      "18103-posttest1-11 1\n",
      "18103-posttest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/34106-posttest0-11-A01.TextGrid\n",
      "sprie kach\n",
      "SEGMENT LIST\n",
      "taar taart strik bloemen betaal schoef waarde spruin l klets genoeg sproeien lach spriekach bommen schuur nu pranter schappen hik hink w waai sneeuwpop zoutje kappen vreest melk\n",
      "34106-posttest0-11 1\n",
      "34106-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/1113-posttest2-44-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "vlo mooi trompelch toe nicht ze onze slepen raampje tussen zanger flits stopla bewaar nieuwtje schroot buiten vondst bank markt spuw\n",
      "1113-posttest2-44 1\n",
      "1113-posttest2-44\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/45102-pretest0-11-A01.TextGrid\n",
      "spi r t\n",
      "ster k\n",
      "sch raal\n",
      "s toep\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spirt ierkracht bal sterk metaal bo onze geit toch jaap schraal genoeg mug rampje deuk schroef mooi muur frank stoep flits\n",
      "45102-pretest0-11 1\n",
      "45102-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33202-posttest1-11-A01.TextGrid\n",
      "stek rk\n",
      "kra kken\n",
      "ziek e\n",
      "rech tas\n",
      "tas f\n",
      "SEGMENT LIST\n",
      "lesje kijken hagl jaap stekrk bestaat dururen dek touchen krakken schrik boomstam warsmst joch web zieke rechtas tas weg rech tasf taf spa sterren nieul jicht vorst stuldam lijn\n",
      "33202-posttest1-11 1\n",
      "33202-posttest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/29105-posttest0-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "draai strik bloemen meetlat schroef waardes sp spreeuw klets genoeg sproeien lach spierkracht bomen schuur nu planter schrapen hink waai sneeuwpop zoutje kappen vreemds melk\n",
      "29105-posttest0-11 1\n",
      "29105-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/37103-posttest2-11-A01.TextGrid\n",
      "s l e p en\n",
      "z a ng e r\n",
      "d e  ken\n",
      "be e\n",
      "u aar\n",
      "mark t\n",
      "SEGMENT LIST\n",
      "vo vlo mooi trom trommel trommel stoep n n nicht nicht onze slepen slepen raampje tussen zanger zanger flits sportkap sportkap deken deken dekken doof hond e p bee uaar bewaar nieuwtje nieuwtje schroot schoot schroot bui buiten vonk vonkst bank arkt markt spuw reis\n",
      "37103-posttest2-11 1\n",
      "37103-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/13110-posttest2-11-A01.TextGrid\n",
      "stro el\n",
      "zag er\n",
      "zag n er\n",
      "SEGMENT LIST\n",
      "volaf mooi stroel stroe stoep nikt ohonze sleppen raampje tussen zager zag zagner fi flits bewaar nieuwtje rood buiten vondst mar reis\n",
      "13110-posttest2-11 1\n",
      "13110-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/13105-pretest0-11-A01.TextGrid\n",
      "spier kr acht\n",
      "sch raal\n",
      "g e oe g\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spierkracht bal sterk meetlat bol onze geit toch jaap schraal ch schraal geoeg genoeg mug raampje deuk schroef mooi muur frank stoep flits\n",
      "13105-pretest0-11 1\n",
      "13105-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/26110-pretest0-12-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "buik web lift gapje bal sterk meetlet meetlet bo ons onze geit toch jaap p schaar schaal genoeg mug raampje deuk schoef mooi muur frank stoep flits\n",
      "26110-pretest0-12 1\n",
      "26110-pretest0-12\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33102-posttest2-11-A01.TextGrid\n",
      "sport bark\n",
      "SEGMENT LIST\n",
      "vlo mooi trommel stoep nicht onze sle slepen raampje tussen zangen flits sportbark dekken dof hond bewaar nieuwtjes schroot buiten wonts bank mark spul reis\n",
      "33102-posttest2-11 1\n",
      "33102-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/25111-pretest2-11-A01.TextGrid\n",
      "st  rik\n",
      "s  pecht\n",
      "buur  ten\n",
      "boom  stam\n",
      "wie  ke\n",
      "SEGMENT LIST\n",
      "jong lach strik vuur specht kee keelpijn sla buurten koud kous pink schuur muis tussen tussen fof fop zwa zwarm zwart koen denk boomstam huis sch schrift blauw hond wieke saus\n",
      "25111-pretest2-11 1\n",
      "25111-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/27105-posttest2-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "vlo mooi tromel trommel stoepe nikst oze onze speewen raampje tuinen zager dus pradal duif hond bewaar nieuwtje schroot buiten worst bang markt spruw reis\n",
      "27105-posttest2-11 1\n",
      "27105-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/32101-pretest0-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spikracht bal sterk meetlat bo zo geit toch jaap schaap genoeg mug raampje deuk schoef mug frank stoep lift\n",
      "32101-pretest0-11 1\n",
      "32101-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/41105-pretest0-22-A01.TextGrid\n",
      "s  t  oe  p\n",
      "SEGMENT LIST\n",
      "buik w web l lift grapje spriekracht bal sterk mees meten bom ons onze geit toch jaap sraal genoeg mug raapje dw deuk schroef mooi muur flank stoel stoep stoep\n",
      "41105-pretest0-22 1\n",
      "41105-pretest0-22\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/41105-posttest0-11-A01.TextGrid\n",
      "sproei en\n",
      "geen tijd\n",
      "SEGMENT LIST\n",
      "dra draad strik bloemen meetlat schroef wa waarde sp spreeuw klets genoeg sproeien lach sp springkracht spie spierkracht bomen schuur nu pat panter panter schap schappen hink haai sneeuwpop zoutje kappen geentijd melk\n",
      "41105-posttest0-11 1\n",
      "41105-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33202-posttest2-11-A01.TextGrid\n",
      "sp ul\n",
      "SEGMENT LIST\n",
      "vol maai tarommel toe t soe ts soep jicht nieuwt nieuwgt zo oze sleppe raapje t tussen zammer flits sportpark do dekken dof hond hond bewaar newutje sol scholoot buiten volndest ba bank markt spul reis\n",
      "33202-posttest2-11 1\n",
      "33202-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/34116-pretest1-11-A01.TextGrid\n",
      "s  t  e  rr  e  n\n",
      "g  a\n",
      "p  r  o  s  t\n",
      "v  l  o\n",
      "b  a\n",
      "p  a  d\n",
      "m  r  k  t\n",
      "SEGMENT LIST\n",
      "pauw st stel sterren sterren ga gat prost praus prost lijn vol vlo vlo kijken lus ba bank sroen pad padden pad mrkt maarkt e eef neef zoutje melk bestaat reis s schrik vang nu waai hout juicht\n",
      "34116-pretest1-11 1\n",
      "34116-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/37112-pretest0-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "buik web lift gapje spierkracht bal sterk m meetlat bo onze guik toch jaap schaar genoeg mug raapje deuk schroef mooi muur franks st stoep wi f flits\n",
      "37112-pretest0-11 1\n",
      "37112-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/13102-pretest0-11-A01.TextGrid\n",
      "ier  p  r  acht\n",
      "t  oche\n",
      "j aa p\n",
      "sch  aa l\n",
      "g  een\n",
      "g  een  noeg\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spi ierpracht bal sterke meetlat bol onze geit toche jaap schr schaal ge geen geennoeg mug raampje deuk schroef mooi muur frank stoep flits\n",
      "13102-pretest0-11 1\n",
      "13102-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/43123-pretest0-11-A01.TextGrid\n",
      "sp ier k kracht\n",
      "sch  h\n",
      "heraai e\n",
      "ge  noeg\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spierkkracht bak sterk mee meetlat bo o onze geit toch jaap sch schh heraaie schraag g genoeg mug raampje deur schroef mooi muur frank stoep\n",
      "43123-pretest0-11 1\n",
      "43123-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/18111-posttest0-11-A01.TextGrid\n",
      "draa  d\n",
      "ke  tent\n",
      "SEGMENT LIST\n",
      "draad strik bloem meetlat schroef waarde speeuw ketent groen proe lachen spriekracht wok schuur nuk pate s hik wh sneeuwpop zout krappen vraamst melk\n",
      "18111-posttest0-11 1\n",
      "18111-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/8112-posttest2-11-A01.TextGrid\n",
      "he nee\n",
      "sle  pen\n",
      "tus  en\n",
      "vlee  ts\n",
      "por  k  t  park\n",
      "s  p oo r t\n",
      "kort paark\n",
      "SEGMENT LIST\n",
      "vlo vlo mooi t tromme sti henee stoep nicht ons onze onze onze slepen raampje tu teun t tusen tussen slang vleets flits s porktpark sportspak sport sp spoort kortpaark paak paark beng beng k peng pengpen dof hond bew nieu reis\n",
      "8112-posttest2-11 1\n",
      "8112-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/34116-posttest0-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "draait strilk bloemen meestaal schoef waarde spreeuw kluwt knoeig sproeien lach spriekkaalt beomen schuurg nu p t pater schapen hik waai sneeuwpop zoutje kappen vermist melk\n",
      "34116-posttest0-11 1\n",
      "34116-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/16101-posttest1-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "lep lesje kijken hagel je jaap ster besta betaal dure denk stoei krui schrik boomstam warmst jong we zieke rechsaf spas sterren nieuw jucht worst stuwl lijn\n",
      "16101-posttest1-11 1\n",
      "16101-posttest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/28107-pretest1-11-A01.TextGrid\n",
      "zou  tje\n",
      "jo  b\n",
      "SEGMENT LIST\n",
      "pauw sterren gats proost lijn vl krijgen lush bank schoen pad markt neef zoutje melk job bestaart reis broek vang nu waai hout jucht\n",
      "28107-pretest1-11 1\n",
      "28107-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/8119-posttest0-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "draad strik bloemen metaal schroef waarde spreeuw klets genoeg sproeien lach spierkracht bo bommen schuur nu panter schrapen hink waai sneeuwpop zoetje zoutje kappen vriedst melk vreemdst melk\n",
      "8119-posttest0-11 1\n",
      "8119-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/10104-posttest2-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "vlo mooi trommel stoep licht onze slepen raampje tussen zanger flits sportspar deken dof hond bewaar nieuwtje schroot buiten vondst bank marks spjuw reis\n",
      "10104-posttest2-11 1\n",
      "10104-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/1113-posttest1-35-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "lesje kijken hang hager jaap sterk bestaat buren buren denk stoei krach krakken kraken schrik boomstam warmst jong web zieke r rechtsaf spa sterk sterren nieuw jeugd vorst stuw studam lijn\n",
      "1113-posttest1-35 1\n",
      "1113-posttest1-35\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/30106-pretest1-11-A01.TextGrid\n",
      "kijk en\n",
      "mar kt\n",
      "jo t\n",
      "bes staat\n",
      "SEGMENT LIST\n",
      "pauw sterk ra ram gat proost lijn blo kijken lus bank luis bl bank schoen pad m markt nee neef nee zoutje melk melk j jot jot besstaat reis schrik vang nu waai hout juicht\n",
      "30106-pretest1-11 1\n",
      "30106-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/30112-pretest1-11-A01.TextGrid\n",
      "SEGMENT LIST\n",
      "pauw sten gas pons lijn vol vo klein lus bank schoen pad bank schoef pand nat neef zoutje melk job bestaart eis schrift vang nu waai hou\n",
      "30112-pretest1-11 1\n",
      "30112-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/24120-posttest2-11-A01.TextGrid\n",
      "vonds t\n",
      "SEGMENT LIST\n",
      "vlo mooi trommel stoep nicht onwus slepen raampje tussen zanger flits sportpark denk deken dof hond bewaar nieuwtje schroot buiten vondst bank markt spuw reis\n",
      "24120-posttest2-11 1\n",
      "24120-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33107-pretest2-11-A01.TextGrid\n",
      "vul sje\n",
      "SEGMENT LIST\n",
      "jong lang strik vuur specht keelpijn style de kuis pink schuur vulsje steem fop za zwaard koen pen boomstam muis schrift blauw hond zin saus\n",
      "33107-pretest2-11 1\n",
      "33107-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/35101-pretest2-11-A02.TextGrid\n",
      "bedoel ik\n",
      "de laatste weet ik niet\n",
      "s tik\n",
      "dat had ik toen ik nieuw op school zat was toen moest ik heel erg hoesten\n",
      "die weet ik niet\n",
      "deze weet ik alweer niet\n",
      "ik moet een klein beetje opschieten want ik heb het gevoel dat we dadelijk moeten gaan gymmen\n",
      "SEGMENT LIST\n",
      "jouch jong bedoelik la delaatsteweetikniet st stik vuur specht keelpijn dathadiktoeniknieuwopschoolzatwastoenmoestikheelerghoesten slat sla dieweetikniet kous pink schuur dezeweetikalweerniet t tussen fop z zw zwawart koen ikmoeteenkleinbeetjeopschietenwantikhebhetgevoeldatwedadelijkmoetengaangymmen deuk boomstam schrift blauw houde ziek zieke s s saus\n",
      "35101-pretest2-11 2\n",
      "35101-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/38107-posttest1-11-A02.TextGrid\n",
      "ju j\n",
      "vor st\n",
      "stuur dau\n",
      "SEGMENT LIST\n",
      "lesje kijken hagel jaap sterk bes bestaal dure denk stoe stoei krach ka kraken schrik boomstam warmst jong web ziek rechtsaf spa sterren nieuw juj juicht vor vorst stuurdau lijn\n",
      "38107-posttest1-11 2\n",
      "38107-posttest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33102-pretest1-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "paw sterren gat proost lijn vlo kijken lus bank schoen pad markt neef zout melk joep bestaa bestaat reis schrik vang nu waar hout juich\n",
      "33102-pretest1-11 2\n",
      "33102-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/13106-pretest1-11-A02.TextGrid\n",
      "s terren\n",
      "n eef\n",
      "mel k\n",
      "best aat\n",
      "r eis\n",
      "SEGMENT LIST\n",
      "pauw sn sterren gapt proost lijn vlo kijken lus bank schoen pal pande markt nee nee neef zoutje melk job job bestaat hm bestaand reis schrik vang nu waai hout\n",
      "13106-pretest1-11 2\n",
      "13106-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/34116-pretest2-11-A02.TextGrid\n",
      "l a ch\n",
      "st ik\n",
      "v uu\n",
      "s p e cht\n",
      "b ui t en\n",
      "s u s\n",
      "f o\n",
      "zw a r t\n",
      "b oo t\n",
      "h hond\n",
      "SEGMENT LIST\n",
      "jong lach lach stik strik vuu vuur specht specht keelpijn s sla buiten buiten kou schuur huisje sus su fo fop zwart zwart koen benk boot boomstam muis schri schrift blauw hhond ziekje saus\n",
      "34116-pretest2-11 2\n",
      "34116-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/8112-posttest0-11-A02.TextGrid\n",
      "s trik\n",
      "m p\n",
      "gen noeg\n",
      "s pierkracht\n",
      "z zou\n",
      "zou tje\n",
      "kra ppen\n",
      "SEGMENT LIST\n",
      "baard baard strik bloemen mp meetlat schroef waardes spreeuw klets goe gennoeg s sproeien lach spierkracht bomen schuur hu nu planten schrapen hi hink wa waai sneeuwpop zzou zoutje zoutje krappen krappen vree vre vreem vreemds vreemdest mel melk\n",
      "8112-posttest0-11 2\n",
      "8112-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/33107-pretest2-11-A02.TextGrid\n",
      "s pet\n",
      "hun sje\n",
      "s ts zeem\n",
      "SEGMENT LIST\n",
      "jong lang strik vuur spet keelpijn stel de kous pink schuur hunsje stszeem fop z zwaart koen ben boomstam muis schrift blauw hond zin saus\n",
      "33107-pretest2-11 2\n",
      "33107-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/21102-pretest2-11-A02.TextGrid\n",
      "pin k\n",
      "zie k\n",
      "SEGMENT LIST\n",
      "jonge jonge jonge jonge lache strik vuur alles buiten kous pink schuur penk p boom boomstam muis schrift blauw hond ziek zieke saus\n",
      "21102-pretest2-11 2\n",
      "21102-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/6101-pretest1-11-A02.TextGrid\n",
      "ster ren\n",
      "ba nk\n",
      "par kt\n",
      "zoe te\n",
      "SEGMENT LIST\n",
      "pauw sterren gat proost lijn vr fol kijken lus bank schoen pand pad parkt neef zoete melk job bestaart reis schrik van nu waa hout jucht\n",
      "6101-pretest1-11 2\n",
      "6101-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/28111-posttest0-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "draait strik bloemen metaal schroef waarde spreeuw klets genoeg sproeien lach spierkracht bomen schuur nu panter schapen hink waai sneeuwpop zoutje kappen vreemds melk melk\n",
      "28111-posttest0-11 2\n",
      "28111-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/36103-posttest2-11-A02.TextGrid\n",
      "sport p pra park\n",
      "SEGMENT LIST\n",
      "vlo mooi trommel stoep nicht onze s slee raampje tussen zagger flits s sportpprapark denk dof hond bewaren nieuwtje schort buiten vondst bank markt spuw reis\n",
      "36103-posttest2-11 2\n",
      "36103-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/16104-posttest2-11-A02.TextGrid\n",
      "zou helpen\n",
      "s sl\n",
      "s p\n",
      "s por t par k\n",
      "dek ken\n",
      "nieuw tje\n",
      "s puw\n",
      "SEGMENT LIST\n",
      "vlooi mooi trommel stoep nicht onz onze s zouhelpen ssl slepen raampje tusjen zag zanger flits sp sportpark dekken doof hond bewaar nieuwtje schrort buiten von vondst bank markt spuw reis\n",
      "16104-posttest2-11 2\n",
      "16104-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/28111-pretest0-11-A02.TextGrid\n",
      "g g\n",
      "SEGMENT LIST\n",
      "buik webs lift gra gg grapje bal sterk meetlat bo onze onze geit toch jaap schraal genoeg m mug raampje deuk schroef mooi muur frank stoep flits\n",
      "28111-pretest0-11 2\n",
      "28111-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/21107-posttest0-11-A02.TextGrid\n",
      "s trik\n",
      "s spreeuw en\n",
      "k app en\n",
      "er v e r\n",
      "SEGMENT LIST\n",
      "draad strik boenen boenen schrijf schroef waarde spreeuw klets genoeg sspreeuwen lach spierkracht bom schuur nu schrappen hink waai sneeuwpop zoutje kappen erver vreemdst melk\n",
      "21107-posttest0-11 2\n",
      "21107-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/25102-pretest2-11-A02.TextGrid\n",
      "lach t\n",
      "lach t\n",
      "s trik\n",
      "s pach t\n",
      "pi k\n",
      "zie ke\n",
      "SEGMENT LIST\n",
      "jong lacht lacht strik vuur spacht keer keelpijn sla buiten kous pik schuur huisje tussen fop zwaard koen den dek boostam muis schrift bla blauw hond zieke saus\n",
      "25102-pretest2-11 2\n",
      "25102-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/44103-posttest0-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "draad strik bloemen meetlat schroef waarde spreeuw klets genoeg sproeien nach spierkracht bomen schuur nu panter schrappen hink waai sneeuwpop zoutje kappen vreemds melk\n",
      "44103-posttest0-11 2\n",
      "44103-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/43111-pretest1-11-A02.TextGrid\n",
      "st erre n r n\n",
      "kij k\n",
      "b enk\n",
      "m a m\n",
      "SEGMENT LIST\n",
      "pauw sterrenrn sterren gat gat pr proost proost lijn lijn vlo vlo kijkt kijk ij kijken kijken les les benk bank sch schoen pad pad pan pand mam\n",
      "43111-pretest1-11 2\n",
      "43111-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/6122-posttest0-11-A02.TextGrid\n",
      "meetla lat\n",
      "g gen\n",
      "spier kracht\n",
      "nu aa\n",
      "schrap en\n",
      "hon k\n",
      "sneeuw pop\n",
      "SEGMENT LIST\n",
      "daard strik bloemen meetlalat schroef waard spreuw kleus ggen genoeg sproeien lach spierkracht bommen schuur nu nuaa panper schrapen honk waai sneeuwpop zoutje kappen melk\n",
      "6122-posttest0-11 2\n",
      "6122-posttest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/13105-pretest0-11-A02.TextGrid\n",
      "gra pje\n",
      "spier kr acht\n",
      "sch raal\n",
      "SEGMENT LIST\n",
      "buik web lift grapje spierkracht bal sterk meetlat bo onze geit toch jaap schraal g schraal genoeg genoeg mug raampje deuk schroef mooi muur frank stoep flits\n",
      "13105-pretest0-11 2\n",
      "13105-pretest0-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/17133-pretest2-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "jon lang lach strik vuur sprecht keelpijn sla buiten kous pink schuur huisje tussen fop zwart koen denk boomstam muis schrift blauw hond ziek saus\n",
      "17133-pretest2-11 2\n",
      "17133-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/20104-pretest2-11-A02.TextGrid\n",
      "keel p\n",
      "keel pijn\n",
      "bosta stam\n",
      "SEGMENT LIST\n",
      "jong lach strik vuur specht keelp keelpijn keelpijn sla buiten kous pit pink schuur huisje tussen fop zwaard koen denk bostastam buis schrif muis schrift blauw hond ziete saus\n",
      "20104-pretest2-11 2\n",
      "20104-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/1208-posttest2-11-A02.TextGrid\n",
      "bedoel ik\n",
      "s l epen\n",
      "weet ik niet\n",
      "weet ik niet\n",
      "s p r\n",
      "s p or t p a k\n",
      "SEGMENT LIST\n",
      "vlol vlo mooi tro trommel s stoep nicht onzin onz ons bedoelik spen speen nee slepen weetikniet raampje tussen zaa zanger vliegtuif sproo vliegtui vliegtuig sprook weetikniet s nee spr sportpak sportpak dekeen deken dof hond bewaar nieuwtje nieuwje schroot bauten nee buiten van fondjust bank markt spun ries\n",
      "1208-posttest2-11 2\n",
      "1208-posttest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/10104-pretest2-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "jong lach strik vuur spe spech s keelpijn sla buiten kous pink schuur huisje tussen fop zwart koen denk boomstam muis schrift blauw hond zieke saus\n",
      "10104-pretest2-11 2\n",
      "10104-pretest2-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/37109-pretest1-11-A02.TextGrid\n",
      "mar kt\n",
      "SEGMENT LIST\n",
      "pa pauw sterre sterren gat spoor sport lijn vlo kijken luis bang schoen pad markt neef zoutje melk job bestaat reis schrik vang nu waai hout\n",
      "37109-pretest1-11 2\n",
      "37109-pretest1-11\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/00_orig_data/textgrids/4121-posttest1-11-A02.TextGrid\n",
      "SEGMENT LIST\n",
      "leesje kijken haggen jaapje sterk bestat ggg denk stoei kraken schrik boomsta warmst jong heb ziek rechtsgaf spa sterren nieuw juikt zorv stuwdam lijn\n",
      "4121-posttest1-11 2\n",
      "4121-posttest1-11\n",
      "56 .json files created in /vol/tensusers2/wharmsen/DART-fluency-features/comp2/06_manual_fluency_features/json-orth-trans\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/06_manual_fluency_features/ot-norm.csv file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-'.?)\n",
      "/vol/tensusers2/wharmsen/DART-fluency-features/comp2/06_manual_fluency_features/ot-all.csv file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-'.?)\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### Define inputs ###\n",
    "#####################\n",
    "\n",
    "corpus = 'dart'\n",
    "basePath = '/vol/tensusers2/wharmsen/DART-fluency-features/comp2'\n",
    "tgFileDir = os.path.join(basePath, '00_orig_data/textgrids')\n",
    "tgFileExtension = '.TextGrid'\n",
    "outputDir = os.path.join(basePath, '06_manual_fluency_features/json-orth-trans')\n",
    "word_tier_name = 'attempts'\n",
    "normalizeNamesAndSpellingErrors = False\n",
    "\n",
    "#########################\n",
    "### Create JSON files ###\n",
    "#########################\n",
    "\n",
    "# Create output dir\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "# Define output transcription files\n",
    "otTrans_norm = []\n",
    "otTrans_allFiles = []\n",
    "outputTranscriptsNormFile = os.path.join(basePath, '06_manual_fluency_features/ot-norm.csv')\n",
    "outputTranscriptsAllFile = os.path.join(basePath, '06_manual_fluency_features/ot-all.csv')\n",
    "\n",
    "# List all .TextGrid files\n",
    "textgridFiles = glob.glob(os.path.join(tgFileDir, '*' + tgFileExtension))\n",
    "print(len(textgridFiles), 'TextGrid files found')\n",
    "\n",
    "for tgFile in textgridFiles:\n",
    "    print(tgFile)\n",
    "\n",
    "    # Read TextGrid file\n",
    "    tg_df = readTextGridFile(tgFile, corpus)\n",
    "    tg_df_orth_trans = selectWordTierTextGrid(tg_df, word_tier_name)\n",
    "\n",
    "    # Split textDF into sentences\n",
    "    sentenceDFList = splitTextDFIntoSentences(tg_df_orth_trans)\n",
    "\n",
    "    if len(sentenceDFList) == 0:\n",
    "        print('EMPTY SENTENCE DF')\n",
    "        print(sentenceDFList)\n",
    "\n",
    "    # Change each sentenceDF to a segment\n",
    "    segmentList = [turnSentenceDFIntoSegment(sentenceDF, sentenceNr) for sentenceNr, sentenceDF in enumerate(sentenceDFList)]\n",
    "\n",
    "    print('SEGMENT LIST')\n",
    "    print(\" \".join([segment['text'] for segment in segmentList]))\n",
    "\n",
    "    # Save output as Dict\n",
    "    tgDict = {\n",
    "        \"text\" : \" \".join([segment['text'] for segment in segmentList]),\n",
    "        \"segments\" : segmentList,\n",
    "    }   \n",
    "\n",
    "    # OUTPUTS\n",
    "    basename = os.path.basename(tgFile).split('-A0')[0]\n",
    "    raterNr = os.path.basename(tgFile).split('-A0')[1][0]\n",
    "\n",
    "    print(basename, raterNr)\n",
    "\n",
    "    # OUTPUT 1: Original transcriptions\n",
    "    # otTrans_allFiles.append([os.path.basename(tgFile).replace('.TextGrid', ''), sclite_norm.normalize_string(tgDict['text'])])\n",
    "    otTrans_allFiles.append([os.path.basename(tgFile).replace('.TextGrid', ''), sclite_norm.normalize_string(tgDict['text'], names_as_prompt=False)])\n",
    "\n",
    "    # For\n",
    "    recID = basename.split('-A')[0]\n",
    "    print(recID)\n",
    "    if recID not in ['10104-posttest2-11', '33107-pretest2-11'] or raterNr == '1':\n",
    "        # otTrans_norm.append([basename, sclite_norm.normalize_string(tgDict['text'])])\n",
    "        otTrans_norm.append([basename, sclite_norm.normalize_string(tgDict['text'], names_as_prompt=False)])\n",
    "\n",
    "\n",
    "    # OUTPUT 2: Write tgDict as json file\n",
    "    outputFile = os.path.join(outputDir, basename + '.json')\n",
    "\n",
    "    # Check if file already exists, if it does, only dump file if current raterNr == 1 (Some files are rated by two raters, we only use the ratings by rater A01 (raterNr = 1))\n",
    "    if (not os.path.exists(outputFile)) or (os.path.exists(outputFile) and raterNr == '1'):\n",
    "        with open(outputFile, \"w\") as outfile:\n",
    "            json.dump(tgDict, outfile, indent=4)\n",
    "\n",
    "print(str(len(glob.glob(os.path.join(outputDir, '*.json')))) + ' .json files created in '+ outputDir)\n",
    "\n",
    "# Write ot-norm file\n",
    "otTrans_norm_DF = pd.DataFrame(otTrans_norm, columns=['audioID', 'orthographic_transcription']).set_index('audioID').sort_index()\n",
    "otTrans_norm_DF.to_csv(outputTranscriptsNormFile)\n",
    "print(outputTranscriptsNormFile, 'file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-\\'.?)')\n",
    "\n",
    "# Write ot-all file\n",
    "otTrans_all_DF = pd.DataFrame(otTrans_allFiles, columns=['audioID', 'orthographic_transcription']).set_index('audioID').sort_index()\n",
    "otTrans_all_DF.to_csv(outputTranscriptsAllFile)\n",
    "print(outputTranscriptsAllFile, 'file created. This file is fully normalized, in contrast to the generated json files, also the basic punctuation is removed (!-\\'.?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv-fluency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
